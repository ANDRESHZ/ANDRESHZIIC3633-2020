# **Critica: Performance of Recommender Algorithms on Top-N Recommendation Tasks**

_**Impresión del Paper:**_ 

> Me intereso bastante el Articulo debido a que su enfoque fue mas a nivel teórico (_lo cual hace su lectura mas entretenida_), y correspondía a una incógnita que yo sostenía respecto a centrare en las recomendaciones visibles la usuario (_Top-N_), la manera en que expresan las razón de introducir las nuevas métricas de medición es clara y adecuada pues el conjunto tanto de evaluación como datos cambia totalmente, donde ahora se cuenta con una “**Ventana**” (_visibilidad del usuario_) sobre la cual se asignan las recomendaciones mas relevantes a un usuario , allí es donde toma importancia la eliminación de algunos reguladores con el fin de manjar resultados en magnitud mayor, lo cual permite realizar una extrapolación de los gustos del usuario.

```[El que mucho abarca poco aprieta, como precepto para PureSVD sobre recomendaciones Top-N].```

Presenta una v**ista adecuada para la recomendación de usuarios** donde deja de centrar su vista en el problema `general de raking global` y se centra en lo que llamaría una empresa: “*la primera linea de venta*” que serian las l**istas TOP-N, bajo las cuales radica el mayor consumo**. Dando en el blanco, pues desde mi perspectiva es verdad (_Nosotros no vemos todas las recomendaciones y entre mas se alejan menos interés tenemos_).

El uso de métricas globales (_RMSE, MAE, RANK..._) sirven para definir que Sistema es mejor en t**érminos generales**, pero si lo que se busca es mejorar aspectos específicos no globales, entrar a **ver la especificad del campo de estudio es lo que marca la diferencia** (*en este caso listas TOP-N*), creo yo allí fue donde Cremonesi et al. dieron en el blanco, pues centraron sus esfuerzos en la problemática especifica del “**Merchandising**”, de la listas a recomendar.

Algo que es totalmente relevante es lo que yo caracterizaría como g**ustos de la comunidad y gustos de usuario**, de los cuales los autores identifican como los encontrados en la **Cabeza** y **Cola Larga** respectivamente, allí se refleja lo adecuado de una comunidad (_los datasets son muestras que describen la comunidad evaluada_), por tanto pese a que en la cabeza existen grandes cantidades de ratings otorgados por la popularidad del elemento evaluado, **en la cola se observan los gustos inherentes a los usuario específicos**, pues por ello no tienen grandes cantidades y son pocas las participaciones de la comunidad global. (_algo que no me quedo claro es como seleccionaron que el 33% es la cabeza, yo usaría alguna relación de densidad de datos_).

La implementación de varios Métodos personalizados (_CorNgbr, NNCosNgbr, AsySVD, SVD++_) y no personalizados (_Movie Avg, TopPop_) denotan l**a calidad y profundidad del trabajo** ademas que a lo largo del documento exponen las características usadas en los métodos, el método _**PureSVD**_ con factores latentes de 50, 150 y 300, muestran diferentes visiones del problema, pese que no se define un método para su selección (_como en lo demás sistemas recomendadores, se deja bajo experiencia le mejor resultado_).

Se definen normas para eliminar la regularización y permitir extrapolar un concepto visto antes (_**Orden total**, donde un objeto es mas preferible que otro siempre_) y así nacen ecuaciones como similaridad encogida  ![simi](https://latex.codecogs.com/gif.latex?d_%7Bij%7D%3D%5Cfrac%7Bn_%7Bij%7D%7D%7Bn_%7Bij%7D&plus;%5Clambda%20_1%7D)), Ranking ![ranking](https://latex.codecogs.com/gif.latex?%5Cleft%20%28%20%28%5Chat%7Br%7D_%7Bui%7D%3Db_%7Bui%7D&plus;%5Csum_%7Bj%5Cin%20D%5Ek%20%28u%3Bi%29%29%7Dd_%7Bij%7D%28r_%7Buj%7D-b_%7Buj%7D%29%20%5Cright%29)
 con el fin de generar un ordenamiento prácticamente automático por valencias de los items.

Los resultados son muy buenos respecto a la simplicidad del método en comparación con otros métodos mucho mas pesados (**computacionalmente**), pero claramente es por que se esta viendo el marco de trabajo actual (_**TOP-N**_) y no el global. Pese a eso **PureSVD** mantiene una buen relación con las características y métricas no estudiadas. La naturaleza del modelo obligo a la **creación de nuevas métricas** con las cuales se definió la efectividad en las listas TOP-N ![Recall](https://latex.codecogs.com/gif.latex?%5Cleft%20%28%20recall%28N%29%3D%5Cfrac%7B%5C%23%20hits%7D%7B%7CT%7C%7D%5C%20%5C%20y%20%5C%20%5C%20presicion%28N%29%3D%5Cfrac%7B%5C%23%20hits%7D%7BN%5Ccdot%20%7CT%7C%7D%20%5Cright%20%29), **permitió la evaluación de estos métodos, dando un resultados adecuados para el sistema creado** y algunos no esperados como el **TopPOP** (e*sto se debe a que esta rankeando sobre una lista de popularidad global, al usar la Cola se ve la clara diferencia*), lo cual impulso distintos experimentos.

**Trabajo a Futuro:** `Se pueden buscar métodos para la cola larga que permitan identificar los gustos de los usuario a nivel especifico a nivel implícito. Ademas de que ellos indican claramente que dejan una puerta abierta para híbridar y optimizar los algoritmos, cuestión no abordada por el paper.`

* > **PD**: Lastima la carencia casi total de la profundidad matemática, pese a que no fue necesaria para el entendimiento del método deja mucho que desear para posibles mejoras a futuro.
