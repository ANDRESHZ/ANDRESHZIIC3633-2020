# **Critica: BPR: Bayesian Personalized Ranking from Implicit Feedback**

_**Impresión del Paper:**_ 

> Un estupendo articulo con una profundidad y claridad matemática excepcional, generan una gran expectativa del método y no es para menos debido a sus resultados, lo cual es increíble pues pese a la profundidad del mismo aplican a diferentes métodos, 2 datasets y con la extrapolación de su método en las diferentes partes (son características que uno desearía se desarrollen  en todas la investigaciones), aun así destaca que debido extensión (corta, para tanto contenido) debió jugar un papel importante viendo la síntesis y claridad, las cuales si expresa el documento siendo muy difíciles de lograr.

```[Síntesis, claridad y a su vez profundidad, claros indicios de una gran investigación =D].```

Comenzare por lo que me extraño del articulo y es que se usaron características implícitas en el mismo, y solo hubo un pequeño espacio en donde se referían a cuáles usarían. Pero claramente es debido a la naturaleza de los datasets (**Rossmann y Netflix**) probados, los cuales contienen esta información.

El apartado matemático tanto de formalización (_entendimiento_) y de optimización del modelo a implementar **brinda una vista clara de un problema complejo de explicar** (_pues se debe desvincular de lo hasta ahora conocido_), pese a que debía detenerme constantemente para realizar la extrapolación de lo que los autores indicaban, **muy pocas dudas quedaban pues indicaban los pasos a buen detalle**. La eliminación de información “_**innecesaria**_” para el modelo queda clara lo cual dejaba un conjunto de datos de entrenamiento ![DS](https://latex.codecogs.com/gif.latex?%5Cdpi%7B120%7D%20%5Clarge%20D_S%3A%3D%5Cleft%20%5C%7B%20%28u%2Ci%2Cj%29%7Ci%5Cin%20I%5E%7B&plus;%7D_u%5Cwedge%20j%5Cin%20I%5Csetminus%20I%5E%7B&plus;%7D_u%20%5Cright%20%5C%7D), lo cual jugo como limitador para evitar mirar ítems  y el corazón de la investigación se centra en la comparación de preferencia sobre ítems ![mayor](https://latex.codecogs.com/gif.latex?%5Cdpi%7B120%7D%20%5Clarge%20i_a%3E_u%20j_b) donde ![aDIFb](https://latex.codecogs.com/gif.latex?%5Cdpi%7B120%7D%20%5Clarge%20a%5Cneq%20b), lo cual consolido el modelo de tamaño ![tam](https://latex.codecogs.com/gif.latex?%5Cdpi%7B120%7D%20%5Clarge%20U%5Ctimes%20I%5Ctimes%20I)  donde se evidenciaban las preferencias latentes de los usuario bajo los datos implícitos de los Data Sets.

El uso de un **gradiente estocástico les permitió solucionar problemas de velocidad de entrenamiento**, lo cual describieron muy bien en el apartado _**4.2**_ y aunque de entrada el uso de gradiente genera un choque respecto a su ecuación, el **Pseudo-código lo presenta de manera imperdible**, lo cual en la figura 5 mostro **resultados contundentes con LearnBPR** (_método propuesto por ellos_).

Al continuar con la lectura no esperaba tal explicación al incluirlos en los demás métodos (_MF, SVD, KNN_), la síntesis implementada, con ecuaciones a las cuales estamos familiarizados permitió comprender claramente **la inyección del método en sus distintas aplicaciones**.

A nivel del **submuestreo** del dataset era predecible respecto a la **indicación de tener menor dispersión de datos en la matriz**, para ofrecer unca comparación de preferencia adecuada entre ítems y usuarios. (_por tanto, el arranque frio es un enemigo de este modelo, pero ellos claramente lo hicieron notar desde el inicio_), además de usar una **desvinculación de los datasets de entrenamiento y pruebas para evitar problemas de sesgo**, así mismo usar características para su repetición en (10 ocasiones) y la selección aleatoria de los datos a desvincular (*usuario-accion*) de ![ItemsPlus](https://latex.codecogs.com/gif.latex?%5Cdpi%7B120%7D%20%5Clarge%20I%5E%7B&plus;%7D_u).

Los resultados indicados revelaron lo importante de la investigación s**uperando a los métodos usados en comparación** (_**BPR-MF, BPR-kNN**_ ~vs~ _WR-MF, SVD-MF, Cosine-kNN_) y en relación al limite de un sistema personalizado se encuentra alejado (_como era de esperar por la naturaleza de los métodos inyectados_), esto se reflejó de igual manera en ambos datasets.

No vi reflejado el uso de métricas implícitas, pero es p**resumible que es debido a la información indicada por los datasets**, la cual se era de naturaleza implícita, Bajo este precepto me adhiero a su conclusión respecto a que **la optimización de los datos y el manejo de estos métodos generan grandes cambios**, lo cual apoya en gran medida los modelos propuestos y evaluados.

**Trabajo a Futuro:** `Se supondria la identificación de mayores métricas implícitas respecto a los datos, pues los historiales de datos usados están muy correlacionados con los ratings finales, lo cual brinda una cercanía a métodos explícitos, habría que mirar su comportamiento con métricas más abstractas` (_usabilidad, tiempos, saltos de páginas…_).

* > **PD**: Las pocas referencias al final del documento sorprende, pese a que hay conocimientos a lo largo del paper que aunque no lo hayan manejado directamente desde la bibliografía, si se incluyese les regalaría un mayor soporte académico a todas la teorías usadas (_en ultimas si se aprendio a lo largo de la vida no fue por serendipia_).